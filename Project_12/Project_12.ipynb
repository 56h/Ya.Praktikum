{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='_1'></a>\n",
    "# 1 Введение "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='_1_1'></a>\n",
    "## 1.1 Постановка задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Заказчик** -- интернет-магазин  \n",
    "  \n",
    "**Задача** -- предложить инструмент, который будет искать токсичные комментарии в описании товаров и отправлять данные описания на модерацию.  \n",
    "В качестве инструмента использовать модель ML. Модель необходимо обучить классифицировать комментарии на позитивные и негативные.  \n",
    "\n",
    "**Метрика качества модели** -- F1  \n",
    "  \n",
    "**Значение метрики качества модели** -- не менее 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='_1_2'></a>\n",
    "## 1.2 Исходные данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='_1_2_1'></a>\n",
    "### 1.2.1 Общее описание\n",
    "Передан набор данных с разметкой о токсичности правок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='_1_2_2'></a>\n",
    "### 1.2.2 Переданные файлы\n",
    "- toxic_comments.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='_1_2_3'></a>\n",
    "### 1.2.3 Описание данных\n",
    "Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='_1_3'></a>\n",
    "## 1.3 План обработки и анализа данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Предобработка данных\n",
    "- обзор данных;\n",
    "- очистка текста;\n",
    "- лемматизация текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Обучение моделей ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2.2 Разделение набора данных на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2.2 Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2.3 Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='_1_4'></a>\n",
    "## 1.4 Пользовательские функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.core.display import HTML\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "pd.options.display.max_rows = 10\n",
    "#pd.options.display.max_columns = 50\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='_2'></a>\n",
    "# 2 Основная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обзор данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0\n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Очистка текста**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    return \" \".join(re.sub(r\"[^a-zA-Z']\", ' ', text).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww He matches this background colour I'm se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man I'm really not trying to edit war It's...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>More I can't make any real suggestions on impr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Congratulations from me as well use the tools ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation Why the edits made under my userna...      0\n",
       "1  D'aww He matches this background colour I'm se...      0\n",
       "2  Hey man I'm really not trying to edit war It's...      0\n",
       "3  More I can't make any real suggestions on impr...      0\n",
       "4  You sir are my hero Any chance you remember wh...      0\n",
       "5  Congratulations from me as well use the tools ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = data['text'].apply(clear_text)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Приведение слов текстов к нижнему регистру**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лемматизация текста**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "\n",
    "def lemmatize(text):\n",
    "    return \"\".join(m.lemmatize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.8 ms, sys: 12.3 ms, total: 24.1 ms\n",
      "Wall time: 910 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"explanation why the edits made under my username hardcore metallica fan were reverted they weren't vandalisms just closure on some gas after i voted at new york dolls fac and please don't remove the template from the talk page since i'm retired now\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lemmatize(data.loc[0, 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизация всего набора данных на имеющихся вычислительных мощностях займёт порядка 1,5 дня. Ограничим выборку 80 000 значениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = RandomState(1457)\n",
    "\n",
    "txt_corpus = data.sample(n=80000, replace=False, random_state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 38s, sys: 9.37 s, total: 8min 48s\n",
      "Wall time: 9min 37s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>157809</td>\n",
       "      <td>i could just give you an email address that i ...</td>\n",
       "      <td>0</td>\n",
       "      <td>i could just give you an email address that i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47841</td>\n",
       "      <td>i totally understand if you ever become intere...</td>\n",
       "      <td>0</td>\n",
       "      <td>i totally understand if you ever become intere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131316</td>\n",
       "      <td>in so far the list shoudlnt be used in the def...</td>\n",
       "      <td>0</td>\n",
       "      <td>in so far the list shoudlnt be used in the def...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35364</td>\n",
       "      <td>hey i didn't come up with that native australi...</td>\n",
       "      <td>1</td>\n",
       "      <td>hey i didn't come up with that native australi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122849</td>\n",
       "      <td>you got someone banned who would want to fool ...</td>\n",
       "      <td>1</td>\n",
       "      <td>you got someone banned who would want to fool ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154274</td>\n",
       "      <td>re cv sorry no copyright violation was made th...</td>\n",
       "      <td>0</td>\n",
       "      <td>re cv sorry no copyright violation was made th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83254</td>\n",
       "      <td>does not dicuss any work towards a universal d...</td>\n",
       "      <td>0</td>\n",
       "      <td>does not dicuss any work towards a universal d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38465</td>\n",
       "      <td>december utc pathoschild i could kiss you a th...</td>\n",
       "      <td>0</td>\n",
       "      <td>december utc pathoschild i could kiss you a th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44648</td>\n",
       "      <td>yeah when you read the black book of buried se...</td>\n",
       "      <td>0</td>\n",
       "      <td>yeah when you read the black book of buried se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42531</td>\n",
       "      <td>see you are just so cute and i can work with y...</td>\n",
       "      <td>0</td>\n",
       "      <td>see you are just so cute and i can work with y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "157809  i could just give you an email address that i ...      0   \n",
       "47841   i totally understand if you ever become intere...      0   \n",
       "131316  in so far the list shoudlnt be used in the def...      0   \n",
       "35364   hey i didn't come up with that native australi...      1   \n",
       "122849  you got someone banned who would want to fool ...      1   \n",
       "154274  re cv sorry no copyright violation was made th...      0   \n",
       "83254   does not dicuss any work towards a universal d...      0   \n",
       "38465   december utc pathoschild i could kiss you a th...      0   \n",
       "44648   yeah when you read the black book of buried se...      0   \n",
       "42531   see you are just so cute and i can work with y...      0   \n",
       "\n",
       "                                                text_lemm  \n",
       "157809  i could just give you an email address that i ...  \n",
       "47841   i totally understand if you ever become intere...  \n",
       "131316  in so far the list shoudlnt be used in the def...  \n",
       "35364   hey i didn't come up with that native australi...  \n",
       "122849  you got someone banned who would want to fool ...  \n",
       "154274  re cv sorry no copyright violation was made th...  \n",
       "83254   does not dicuss any work towards a universal d...  \n",
       "38465   december utc pathoschild i could kiss you a th...  \n",
       "44648   yeah when you read the black book of buried se...  \n",
       "42531   see you are just so cute and i can work with y...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in txt_corpus.index:\n",
    "    txt_corpus.loc[i, 'text_lemm'] = lemmatize(txt_corpus.loc[i, 'text'])\n",
    "\n",
    "txt_corpus.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Промежуточный итог***  \n",
    "  \n",
    "В ходе предобработки данных:\n",
    "- была проведена очистка текстов;\n",
    "- слова текстов приведены к нижнему регистру;\n",
    "- была проведена лемматизация слов текстов, при этом, в силу больших временных затрат на леммитизацию всего набора, было принято решение о выделии набора размером 80 000 текстов и лемматизация была проведена для него. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Обучение моделей ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Разделение набора данных на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = txt_corpus['text_lemm']\n",
    "target = txt_corpus['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_valid, target_train, target_valid = train_test_split(features,\n",
    "                                                                              target, test_size=0.2, random_state=1457)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words = stopwords)\n",
    "\n",
    "features_train = count_tf_idf.fit_transform(features_train)\n",
    "features_valid = count_tf_idf.transform(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество \"1\": 10.10%\n"
     ]
    }
   ],
   "source": [
    "print('Количество \"1\": {:.2%}'.format(target_train.sum() / len(target_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классы целевого признака не сбалансированы. Этот факт необходимо учитывать при построении моделей ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 4, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.7549281756692047\n",
      "CPU times: user 1min 58s, sys: 1min 19s, total: 3min 17s\n",
      "Wall time: 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logreg_model = LogisticRegression(class_weight = 'balanced', #solver='liblinear', \n",
    "                                  random_state=1457)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [2, 4, 6],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "}\n",
    "\n",
    "CV_result = GridSearchCV(estimator=logreg_model, param_grid=param_grid, scoring='f1', cv=3)\n",
    "\n",
    "CV_result.fit(features_train, target_train)\n",
    "\n",
    "print(CV_result.best_params_)\n",
    "print(CV_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7511792452830188\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(C=4, \n",
    "                                  class_weight = 'balanced', \n",
    "                                  penalty='l1',\n",
    "                                  random_state=1457)\n",
    "logreg_model.fit(features_train, target_train)\n",
    "print('F1:', f1_score(target_valid, logreg_model.predict(features_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7763975155279503\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(C=4, \n",
    "                                  #class_weight = 'balanced', \n",
    "                                  penalty='l1',\n",
    "                                  random_state=1457)\n",
    "logreg_model.fit(features_train, target_train)\n",
    "print('F1:', f1_score(target_valid, logreg_model.predict(features_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 100, 'n_estimators': 150}\n",
      "0.5354062664608791\n",
      "CPU times: user 22min 59s, sys: 0 ns, total: 22min 59s\n",
      "Wall time: 23min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "random_forest_model = RandomForestClassifier(class_weight = 'balanced', random_state=1457)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [10, 100, 150],\n",
    "    'max_depth' : [10, 50, 100]\n",
    "}\n",
    "\n",
    "CV_result = GridSearchCV(estimator=random_forest_model, param_grid=param_grid, scoring='f1', cv=3)\n",
    "\n",
    "CV_result.fit(features_train, target_train)\n",
    "\n",
    "print(CV_result.best_params_)\n",
    "print(CV_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.5301080802882142\n"
     ]
    }
   ],
   "source": [
    "random_forest_model = RandomForestClassifier(random_state = 1457, class_weight = 'balanced', max_depth=100, n_estimators=150)\n",
    "random_forest_model.fit(features_train, target_train)\n",
    "print('F1:', f1_score(target_valid, random_forest_model.predict(features_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Промежуточный итог***  \n",
    "  \n",
    "По итогам обучения моделей ML можно сделать следующие выводы:\n",
    "- лучшее качество получено на модели логистической регрессии;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе выполнения работы было сделано следующее.  \n",
    "  \n",
    "В ходе предобработки данных:\n",
    "- была проведена очистка текстов;\n",
    "- слова текстов были приведены к нижнему регистру;\n",
    "- была проведена лемматизация слов текстов, при этом, в силу больших временных затрат на леммитизацию всего набора, было принято решение о выделии набора размером 80 000 текстов и лемматизация была проведена для него.\n",
    "  \n",
    "По итогам обучения моделей ML были сделаны следующие выводы:\n",
    "- лучшее качество получено на модели логистической регрессии;\n",
    "  \n",
    "***Таким образом, для предсказания токсичности комментариев в описании товаров необходимо использовать модель логистической регрессии.***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "376.771px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
